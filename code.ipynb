{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Environment setup\n",
    "!pip -q install llama-cpp-python codecarbon\n",
    "\n",
    "!mkdir -p /root/models/mistral\n",
    "!wget -q -O /root/models/mistral/mistral-7b-instruct-v0.1.Q4_K_M.gguf \\\n",
    "        https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF/resolve/main/mistral-7b-instruct-v0.1.Q4_K_M.gguf\n",
    "\n",
    "# 2) Imports\n",
    "from codecarbon import EmissionsTracker\n",
    "from llama_cpp import Llama\n",
    "import time\n",
    "\n",
    "# 3) Start emissions tracker (keep the record only in memory)\n",
    "tracker = EmissionsTracker(project_name=\"CarbonSwipe-single-run\",\n",
    "                           log_level=\"error\", save_to_file=False)\n",
    "tracker.start()\n",
    "\n",
    "# 4) Load the quantised Mistral-7B model (set seed for reproducibility)\n",
    "llm = Llama(\n",
    "    model_path=\"/root/models/mistral/mistral-7b-instruct-v0.1.Q4_K_M.gguf\",\n",
    "    n_gpu_layers=35,          # adjust to your GPU VRAM\n",
    "    n_ctx=2048,\n",
    "    seed=42,                  # <<< reproducible sampling\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# 5) Prompt and inference\n",
    "prompt = \"Explain how AI can help reduce carbon emissions.\"\n",
    "t0 = time.time()\n",
    "out = llm(prompt, max_tokens=100, stop=[\"</s>\"])\n",
    "t1 = time.time()\n",
    "\n",
    "# 6) Stop tracker and fetch metrics\n",
    "tracker.stop()\n",
    "energy_kwh = tracker.final_emissions_data.energy_consumed\n",
    "co2_kg     = tracker.final_emissions_data.emissions\n",
    "\n",
    "# 7) Display\n",
    "print(\" Model output:\\n\", out[\"choices\"][0][\"text\"].strip())\n",
    "print(f\"\\n Inference time: {(t1 - t0):.2f} s\")\n",
    "print(f\" Energy used:    {energy_kwh * 1_000:.3f} Wh\")\n",
    "print(f\" CO₂ emitted:    {co2_kg   * 1_000:.3f} g\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import time\n",
    "from codecarbon import EmissionsTracker\n",
    "from llama_cpp import Llama\n",
    "import os\n",
    "\n",
    "# Load prompts\n",
    "with open(\"mnt/Benchmark_Prompts.csv\", \"r\") as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    prompts = [row[\"prompt\"] for row in reader]\n",
    "\n",
    "# Initialize model\n",
    "llm = Llama(\n",
    "    model_path=\"/root/models/mistral/mistral-7b-instruct-v0.1.Q4_K_M.gguf\",\n",
    "    n_gpu_layers=35,\n",
    "    n_ctx=2048,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# Prepare results file (create if not exists)\n",
    "results_path = \"mnt/benchmark_results.csv\"\n",
    "write_header = not os.path.exists(results_path)\n",
    "\n",
    "with open(results_path, \"a\", newline='') as f:\n",
    "    fieldnames = [\"index\", \"prompt\", \"output\", \"inference_time_sec\", \"energy_Wh\", \"co2_g\"]\n",
    "    writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "    if write_header:\n",
    "        writer.writeheader()\n",
    "\n",
    "    total = len(prompts)\n",
    "    for i, prompt in enumerate(prompts[:150]):\n",
    "        print(f\"\\n [{i+1}/{total}] Running inference for prompt #{i+1}...\")\n",
    "        tracker = EmissionsTracker(project_name=\"CarbonSwipe-Benchmark\", output_dir=\".\", log_level=\"error\")\n",
    "        tracker.start()\n",
    "\n",
    "        start = time.time()\n",
    "        output = llm(prompt, max_tokens=150, stop=[\"</s>\"])\n",
    "        end = time.time()\n",
    "\n",
    "        tracker.stop()\n",
    "\n",
    "        # Read last row of emissions\n",
    "        with open(\"emissions.csv\", \"r\") as efile:\n",
    "            emissions_reader = csv.DictReader(efile)\n",
    "            last = list(emissions_reader)[-1]\n",
    "            energy_kwh = float(last[\"energy_consumed\"])\n",
    "            co2_kg = float(last[\"emissions\"])\n",
    "\n",
    "        inf_time = round(end - start, 2)\n",
    "        energy_Wh = round(energy_kwh * 1000, 3)\n",
    "        co2_g = round(co2_kg * 1000, 3)\n",
    "\n",
    "        # Write to CSV\n",
    "        writer.writerow({\n",
    "            \"index\": i + 1,\n",
    "            \"prompt\": prompt,\n",
    "            \"output\": output[\"choices\"][0][\"text\"].strip(),\n",
    "            \"inference_time_sec\": inf_time,\n",
    "            \"energy_Wh\": energy_Wh,\n",
    "            \"co2_g\": co2_g\n",
    "        })\n",
    "\n",
    "        # Show live progress\n",
    "        print(f\"⏱ Time: {inf_time:.2f} sec |  Energy: {energy_Wh} Wh |  CO₂: {co2_g} g\")\n",
    "        remaining = total - (i + 1)\n",
    "        est_left = int((end - start) * remaining)\n",
    "        print(f\" Estimated time remaining: {est_left // 60} min {est_left % 60} sec\")\n",
    "        print(\"----------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pathlib, textwrap\n",
    "\n",
    "#  1. Load & enrich data \n",
    "CSV_PATH = pathlib.Path(\"/mnt/benchmark_results.csv\")\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "# Basic derived columns\n",
    "df[\"Output_length\"] = df[\"output\"].str.split().str.len()\n",
    "df[\"Input_length\"]  = df[\"prompt\"].str.split().str.len()\n",
    "df.rename(columns={\"inference_time_sec\": \"Latency_s\"}, inplace=True)\n",
    "\n",
    "# Optional: prompt-category if you stored it elsewhere\n",
    "# Here we fall back to a dummy “Unknown” label\n",
    "if \"Category\" not in df.columns:\n",
    "    df[\"Category\"] = \"Unknown\"\n",
    "\n",
    "# - 2. Matplotlib / seaborn style \n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams.update({\"figure.dpi\": 120})\n",
    "\n",
    "#  3. Figure 1 – energy histogram \n",
    "plt.figure()\n",
    "sns.histplot(df[\"energy_Wh\"], bins=30, kde=True)\n",
    "plt.xlabel(\"Energy per query (Wh)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(textwrap.fill(\"Distribution of energy consumption per query\", 40))\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"yo1.png\")\n",
    "\n",
    "#  4. Figure 2 – correlation heat-map \n",
    "plt.figure()\n",
    "corr = df[[\"energy_Wh\", \"co2_g\", \"Latency_s\",\n",
    "           \"Input_length\", \"Output_length\"]].corr()\n",
    "sns.heatmap(corr, annot=True, cmap=\"coolwarm\", vmin=-1, vmax=1, square=True)\n",
    "plt.title(\"Correlation matrix of key metrics\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"yo2.png\")\n",
    "\n",
    "#  5. Figure 3 – energy vs output length \n",
    "plt.figure()\n",
    "plt.scatter(df[\"Output_length\"], df[\"energy_Wh\"], alpha=0.6)\n",
    "plt.xlabel(\"Output length (tokens)\")\n",
    "plt.ylabel(\"Energy per query (Wh)\")\n",
    "plt.title(\"Energy vs. output length\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"yo3.png\")\n",
    "\n",
    "#  6. Figure 4 – energy vs input length \n",
    "plt.figure()\n",
    "plt.scatter(df[\"Input_length\"], df[\"energy_Wh\"], alpha=0.6)\n",
    "plt.xlabel(\"Input length (tokens)\")\n",
    "plt.ylabel(\"Energy per query (Wh)\")\n",
    "plt.title(\"Energy vs. input length\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"yo4.png\")\n",
    "\n",
    "# 7. Figure 5 – box-plot by category \n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.boxplot(x=\"Category\", y=\"energy_Wh\", data=df)\n",
    "plt.ylabel(\"Energy per query (Wh)\")\n",
    "plt.title(\"Energy consumption by prompt category\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"yo5.png\")\n",
    "\n",
    "# 8. Figure 6 – mean energy bar-plot \n",
    "plt.figure(figsize=(8, 4))\n",
    "df_mean = df.groupby(\"Category\")[\"energy_Wh\"].mean().reset_index()\n",
    "sns.barplot(x=\"Category\", y=\"energy_Wh\", data=df_mean)\n",
    "plt.ylabel(\"Mean energy (Wh)\")\n",
    "plt.title(\"Mean energy per prompt category\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"yo6.png\")\n",
    "\n",
    "print(\" All plots saved\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
